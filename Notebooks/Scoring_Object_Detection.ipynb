{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object Detection for hand-writing using CVTK (AML Package for Computer Vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tz2018\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tz2018\\AppData\\local\\AmlWorkbench\\Python\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from cvtk.utils import detection_utils\n",
    "from cvtk.core import ObjectDetectionDataset\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen model written to path: D:/Projects/EY/models/frozen_inference_graph.pb\n",
      "Labels written to path: D:/Projects/EY/models/label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "frozen_model_path = '<path to frozen_inference_graph.pb>'\n",
    "label_map_path = '<path to label_map.pbtxt>'\n",
    "\n",
    "# frozen_model_path, label_map_path = my_detector.save(model_dir)\n",
    "print(\"Frozen model written to path: \" + frozen_model_path)\n",
    "print(\"Labels written to path: \" + label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_json_filename = '<vott output json file>' \n",
    "label_dict = {'signature':1, 'others':2} # label dictionary\n",
    "jpg_folder = '<path to test images>'\n",
    "output_path = '<results path>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all test image names and paths\n",
    "image_paths  = []\n",
    "image_names = []\n",
    "for img_file in next(os.walk(jpg_folder))[2]:\n",
    "    img_path = os.path.join(jpg_folder, img_file)\n",
    "    image_paths.append(img_path)\n",
    "    image_names.append(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this step will takes while to score each image\n",
    "detections = detection_utils.score_multiple(frozen_model_path, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load VOTT json file\n",
    "with open(out_json_filename) as f:\n",
    "    d = json.load(f)\n",
    "metadata = d['frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As the height and width per image are different, retrieve the height and width for each test image\n",
    "height_dic = dict()\n",
    "width_dic = dict()\n",
    "\n",
    "for index in range(len(image_names)):\n",
    "    img_name = image_names[index]\n",
    "    for i in range(len(metadata[str(index)])):\n",
    "        det = metadata[str(index)][i]\n",
    "        height_dic[img_name] = det['height']\n",
    "        width_dic[img_name] = det['width']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function for calculating precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_iou(values):\n",
    "    bboxes = {}\n",
    "    bboxes['x1'] = values['bbox_1']\n",
    "    bboxes['x2'] = values['bbox_3']\n",
    "    bboxes['y1'] = values['bbox_0']\n",
    "    bboxes['y2'] = values['bbox_2']\n",
    "    return bboxes\n",
    "\n",
    "def cal_precision_recall_matrix(img):\n",
    "    val_values = groundtruth_values[groundtruth_values['image'] == img]\n",
    "    model_values = predicted_values[predicted_values['image'] == img]\n",
    "#     print ('num of true boxes {}; num of detected boxes {}'.format(len(val_values), len(model_values)))\n",
    "    d_matrix = np.zeros((im_height,im_width))\n",
    "\n",
    "    if len(val_values) ==0 and len(model_values) == 0:\n",
    "        precision = 'NA'\n",
    "        recall = 'NA'\n",
    "    elif len(model_values) == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    elif len(val_values) == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    else:\n",
    "        for di in range(len(model_values)):\n",
    "            detect = prepare_iou(model_values.iloc[di])\n",
    "            x1, x2, y1, y2 = int(detect['x1']), int(detect['x2']), int(detect['y1']), int(detect['y2'])\n",
    "            d_matrix[y1:y2+1, x1:x2+1] =1\n",
    "            detect_area = int(d_matrix.sum())\n",
    "        \n",
    "        g_matrix = np.zeros((im_height, im_width))\n",
    "        \n",
    "        for ti in range(len(val_values)):\n",
    "            gtruth = prepare_iou(val_values.iloc[ti])\n",
    "            x1, x2, y1, y2 = int(gtruth['x1']), int(gtruth['x2']), int(gtruth['y1']), int(gtruth['y2'])\n",
    "            g_matrix[y1:y2+1, x1:x2+1] = 1    \n",
    "            g_area = int(g_matrix.sum())\n",
    "        \n",
    "        inter_area = (d_matrix * g_matrix).sum()\n",
    "        precision = inter_area/detect_area\n",
    "        recall = inter_area/g_area     \n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate precision and recall per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate precision and recall for label: signature\n",
      "write results to D:/Projects/EY/results\\signature.csv\n",
      "calculate precision and recall for label: others\n",
      "write results to D:/Projects/EY/results\\others.csv\n"
     ]
    }
   ],
   "source": [
    "for label in list(label_dict.keys()):\n",
    "    \n",
    "    print ('calculate precision and recall for label: {}'.format(label))\n",
    "    \n",
    "    ## load groundtruth handwriting boxes\n",
    "    logfile = []\n",
    "    for index in range(len(image_names)):\n",
    "        img_name = image_names[index]\n",
    "        for i in range(len(metadata[str(index)])):\n",
    "            det = metadata[str(index)][i]\n",
    "            if det['tags'] == [label]:\n",
    "                bbox_1 = det['x1'] # xmin\n",
    "                bbox_0 = det['y1'] # ymin\n",
    "                bbox_3 = det['x2'] # xmax\n",
    "                bbox_2 = det['y2'] # ymax\n",
    "\n",
    "                line = [img_name, bbox_0, bbox_1, bbox_2, bbox_3]\n",
    "                height_dic[img_name] = det['height']\n",
    "                width_dic[img_name] = det['width']\n",
    "\n",
    "                logfile.append(line)\n",
    "\n",
    "    groundtruth_values = pd.DataFrame(logfile)\n",
    "    groundtruth_values.columns = ['image', 'bbox_0', 'bbox_1', 'bbox_2', 'bbox_3']\n",
    "    groundtruth_values.head()\n",
    "    \n",
    "    ## load predicted handwriting boxes\n",
    "    line = []\n",
    "\n",
    "    for index in range(len(detections)):\n",
    "        detect_dict = detections[index]\n",
    "        image_name = image_paths[index].split('\\\\')[-1]\n",
    "\n",
    "        n_obj = 0\n",
    "        detect_index = [] # record the detection index in the detections_dict\n",
    "        im_height = height_dic[image_name]\n",
    "        im_width = width_dic[image_name]\n",
    "        for i in range(detect_dict['num_detections']):\n",
    "            if detect_dict['detection_classes'][i] ==label_dict[label] and detect_dict['detection_scores'][i] > 0.5:\n",
    "                detect_index.append(i)\n",
    "                n_obj += 1\n",
    "                ymin, xmin, ymax, xmax = detect_dict['detection_boxes'][i][0]*im_height, detect_dict['detection_boxes'][i][1]*im_width, \\\n",
    "                    detect_dict['detection_boxes'][i][2]*im_height, detect_dict['detection_boxes'][i][3]*im_width\n",
    "                (left, right, bottom, top) = (xmin, xmax, ymin, ymax)\n",
    "                line.append([image_name, detect_dict['detection_scores'][i], bottom, left, top, right])\n",
    "\n",
    "    predicted_values = pd.DataFrame(line)\n",
    "    predicted_values.columns = ['image', 'score', 'bbox_0', 'bbox_1', 'bbox_2', 'bbox_3']\n",
    "    predicted_values.head()\n",
    "    \n",
    "    ## calculate precision and recall\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for img in image_names:\n",
    "        precision_per_img, recall_per_img = cal_precision_recall_matrix(img)\n",
    "        precision.append(precision_per_img)\n",
    "        recall.append(recall_per_img)\n",
    "        \n",
    "    ## save output\n",
    "    output = pd.concat([pd.DataFrame(precision), pd.DataFrame(recall)], axis = 1)\n",
    "    output.columns = ['precision', 'recall']\n",
    "    \n",
    "    print ('write results to {}'.format(os.path.join(output_path, label+'.csv')))\n",
    "    output.to_csv(os.path.join(output_path, label+'.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
